{
	"AmplitudeEnvelope": {
		"description": "Tone.AmplitudeEnvelope is a Tone.Envelope connected to a gain node.\n         Unlike Tone.Envelope, which outputs the envelope's value, Tone.AmplitudeEnvelope accepts\n         an audio signal as the input and will apply the envelope to the amplitude\n         of the signal. Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "The amount of time it takes for the envelope to go from\n                              0 to it's maximum value.",
				"name": "attack"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The period of time after the attack that it takes for the envelope\n                      \tto fall to the sustain value.",
				"name": "decay"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The percent of the maximum value that the envelope rests at until\n                               \tthe release is triggered.",
				"name": "sustain"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The amount of time after the release is triggered it takes to reach 0.",
				"name": "release"
			}
		],
		"examples": [
			"var ampEnv = new Tone.AmplitudeEnvelope({\n\t\"attack\": 0.1,\n\t\"decay\": 0.2,\n\t\"sustain\": 1.0,\n\t\"release\": 0.8\n}).toMaster();\n//create an oscillator and connect it\nvar osc = new Tone.Oscillator().connect(ampEnv).start();\n//trigger the envelopes attack and release \"8t\" apart\nampEnv.triggerAttackRelease(\"8t\");"
		],
		"extends": "Tone.Envelope"
	},
	"Compressor": {
		"description": "Tone.Compressor is a thin wrapper around the Web Audio\n        [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).\n        Compression reduces the volume of loud sounds or amplifies quiet sounds\n        by narrowing or \"compressing\" an audio signal's dynamic range.\n        Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).",
		"params": [
			{
				"type": [
					"Decibels",
					"Object"
				],
				"optional": true,
				"description": "The value above which the compression starts to be applied.",
				"name": "threshold"
			},
			{
				"type": [
					"Positive"
				],
				"optional": true,
				"description": "The gain reduction ratio.",
				"name": "ratio"
			}
		],
		"examples": [
			"var comp = new Tone.Compressor(-30, 3);"
		],
		"extends": "Tone.AudioNode"
	},
	"EQ3": {
		"description": "Tone.EQ3 is a three band EQ with control over low, mid, and high gain as\n        well as the low and high crossover frequencies.",
		"params": [
			{
				"type": [
					"Decibels",
					"Object"
				],
				"optional": true,
				"description": "The gain applied to the lows.",
				"name": "lowLevel"
			},
			{
				"type": [
					"Decibels"
				],
				"optional": true,
				"description": "The gain applied to the mid.",
				"name": "midLevel"
			},
			{
				"type": [
					"Decibels"
				],
				"optional": true,
				"description": "The gain applied to the high.",
				"name": "highLevel"
			}
		],
		"examples": [
			"var eq = new Tone.EQ3(-10, 3, -20);"
		],
		"extends": "Tone.AudioNode"
	},
	"FFT": {
		"description": "Get the current waveform data of the connected audio source.",
		"params": [
			{
				"type": [
					"Number"
				],
				"optional": true,
				"description": "The size of the FFT. Value must be a power of\n                      two in the range 32 to 32768.",
				"name": "size"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"FeedbackCombFilter": {
		"description": "Comb filters are basic building blocks for physical modeling. Read more\n        about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "The delay time of the filter.",
				"name": "delayTime"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The amount of feedback the filter has.",
				"name": "resonance"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"Filter": {
		"description": "Tone.Filter is a filter which allows for all of the same native methods\n         as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).\n         Tone.Filter has the added ability to set the filter rolloff at -12\n         (default), -24 and -48.",
		"params": [
			{
				"type": [
					"Frequency",
					"Object"
				],
				"optional": true,
				"description": "The cutoff frequency of the filter.",
				"name": "frequency"
			},
			{
				"type": [
					"string"
				],
				"optional": true,
				"description": "The type of filter.",
				"name": "type"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "The drop in decibels per octave after the cutoff frequency.\n                           3 choices: -12, -24, and -48",
				"name": "rolloff"
			}
		],
		"examples": [
			"var filter = new Tone.Filter(200, \"highpass\");"
		],
		"extends": "Tone.AudioNode"
	},
	"Gate": {
		"description": "Tone.Gate only passes a signal through when the incoming\n         signal exceeds a specified threshold. To do this, Gate uses\n         a Tone.Follower to follow the amplitude of the incoming signal.\n         A common implementation of this class is a [Noise Gate](https://en.wikipedia.org/wiki/Noise_gate).",
		"params": [
			{
				"type": [
					"Decibels",
					"Object"
				],
				"optional": true,
				"description": "The threshold above which the gate will open.",
				"name": "threshold"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The follower's attack time",
				"name": "attack"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The follower's release time",
				"name": "release"
			}
		],
		"examples": [
			"var gate = new Tone.Gate(-30, 0.2, 0.3).toMaster();\nvar mic = new Tone.UserMedia().connect(gate);\n//the gate will only pass through the incoming\n//signal when it's louder than -30db"
		],
		"extends": "Tone.AudioNode"
	},
	"Limiter": {
		"description": "Tone.Limiter will limit the loudness of an incoming signal.\n        It is composed of a Tone.Compressor with a fast attack\n        and release. Limiters are commonly used to safeguard against\n        signal clipping. Unlike a compressor, limiters do not provide\n        smooth gain reduction and almost completely prevent\n        additional gain above the threshold.",
		"params": [
			{
				"type": [
					"number"
				],
				"description": "The theshold above which the limiting is applied.",
				"name": "threshold"
			}
		],
		"examples": [
			"var limiter = new Tone.Limiter(-6);"
		],
		"extends": "Tone.AudioNode"
	},
	"LowpassCombFilter": {
		"description": "Tone.Lowpass is a lowpass feedback comb filter. It is similar to\n        Tone.FeedbackCombFilter, but includes a lowpass filter.",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "The delay time of the comb filter",
				"name": "delayTime"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The resonance (feedback) of the comb filter",
				"name": "resonance"
			},
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "The cutoff of the lowpass filter dampens the\n                               signal as it is fedback.",
				"name": "dampening"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"Merge": {
		"description": "Tone.Merge brings two signals into the left and right\n         channels of a single stereo channel.",
		"examples": [
			"var merge = new Tone.Merge().toMaster();\n//routing a sine tone in the left channel\n//and noise in the right channel\nvar osc = new Tone.Oscillator().connect(merge.left);\nvar noise = new Tone.Noise().connect(merge.right);\n//starting our oscillators\nnoise.start();\nosc.start();"
		],
		"extends": "Tone.AudioNode"
	},
	"Meter": {
		"description": "Tone.Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)\n         of an input signal with some averaging applied. It can also get the raw\n         value of the input signal.",
		"params": [
			{
				"type": [
					"Number"
				],
				"description": "The amount of smoothing applied between frames.",
				"name": "smoothing"
			}
		],
		"examples": [
			"var meter = new Tone.Meter();\nvar mic = new Tone.UserMedia().open();\n//connect mic to the meter\nmic.connect(meter);\n//the current level of the mic input in decibels\nvar level = meter.getValue();"
		],
		"extends": "Tone.AudioNode"
	},
	"MidSideCompressor": {
		"description": "Tone.MidSideCompressor applies two different compressors to the mid\n        and side signal components. See Tone.MidSideSplit.",
		"params": [
			{
				"type": [
					"Object"
				],
				"description": "The options that are passed to the mid and side\n                         compressors.",
				"name": "options"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"Mono": {
		"description": "Tone.Mono coerces the incoming mono or stereo signal into a mono signal\n        where both left and right channels have the same value. This can be useful\n        for [stereo imaging](https://en.wikipedia.org/wiki/Stereo_imaging).",
		"extends": "Tone.AudioNode"
	},
	"MultibandCompressor": {
		"description": "A compressor with seperate controls over low/mid/high dynamics",
		"params": [
			{
				"type": [
					"Object"
				],
				"description": "The low/mid/high compressor settings.",
				"name": "options"
			}
		],
		"examples": [
			"var multiband = new Tone.MultibandCompressor({\n \t\"lowFrequency\" : 200,\n \t\"highFrequency\" : 1300\n \t\"low\" : {\n \t\t\"threshold\" : -12\n \t}\n })"
		],
		"extends": "Tone.AudioNode"
	},
	"MultibandSplit": {
		"description": "Split the incoming signal into three bands (low, mid, high)\n        with two crossover frequency controls.",
		"params": [
			{
				"type": [
					"Frequency",
					"Object"
				],
				"optional": true,
				"description": "the low/mid crossover frequency",
				"name": "lowFrequency"
			},
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "the mid/high crossover frequency",
				"name": "highFrequency"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"PanVol": {
		"description": "Tone.PanVol is a Tone.Panner and Tone.Volume in one.",
		"params": [
			{
				"type": [
					"AudioRange"
				],
				"description": "the initial pan",
				"name": "pan"
			},
			{
				"type": [
					"number"
				],
				"description": "The output volume.",
				"name": "volume"
			}
		],
		"examples": [
			"//pan the incoming signal left and drop the volume\nvar panVol = new Tone.PanVol(-0.25, -12);"
		],
		"extends": "Tone.AudioNode"
	},
	"Split": {
		"description": "Tone.Split splits an incoming signal into left and right channels.",
		"examples": [
			"var split = new Tone.Split();\nstereoSignal.connect(split);"
		],
		"extends": "Tone.AudioNode"
	},
	"Volume": {
		"description": "Tone.Volume is a simple volume node, useful for creating a volume fader.",
		"params": [
			{
				"type": [
					"Decibels"
				],
				"optional": true,
				"defaultvalue": 0,
				"description": "the initial volume",
				"name": "volume"
			}
		],
		"examples": [
			"var vol = new Tone.Volume(-12);\ninstrument.chain(vol, Tone.Master);"
		],
		"extends": "Tone.AudioNode"
	},
	"Waveform": {
		"description": "Get the current waveform data of the connected audio source.",
		"params": [
			{
				"type": [
					"Number"
				],
				"optional": true,
				"description": "The size of the FFT. Value must be a power of\n                      two in the range 32 to 32768.",
				"name": "size"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"Analyser": {
		"description": "Wrapper around the native Web Audio's\n         [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).\n         Extracts FFT or Waveform data from the incoming signal.",
		"params": [
			{
				"type": [
					"String"
				],
				"optional": true,
				"description": "The return type of the analysis, either \"fft\", or \"waveform\".",
				"name": "type"
			},
			{
				"type": [
					"Number"
				],
				"optional": true,
				"description": "The size of the FFT. Value must be a power of\n                      two in the range 32 to 32768.",
				"name": "size"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"CrossFade": {
		"description": "Tone.Crossfade provides equal power fading between two inputs.\n        More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).",
		"params": [
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"defaultvalue": 0.5,
				"name": "initialFade"
			}
		],
		"examples": [
			"var crossFade = new Tone.CrossFade(0.5);\n//connect effect A to crossfade from\n//effect output 0 to crossfade input 0\neffectA.connect(crossFade, 0, 0);\n//connect effect B to crossfade from\n//effect output 0 to crossfade input 1\neffectB.connect(crossFade, 0, 1);\ncrossFade.fade.value = 0;\n// ^ only effectA is output\ncrossFade.fade.value = 1;\n// ^ only effectB is output\ncrossFade.fade.value = 0.5;\n// ^ the two signals are mixed equally."
		],
		"extends": "Tone.AudioNode"
	},
	"Envelope": {
		"description": "Tone.Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)\n         envelope generator. Tone.Envelope outputs a signal which\n         can be connected to an AudioParam or Tone.Signal.\n         <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ea/ADSR_parameter.svg\">",
		"params": [
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The amount of time it takes for the envelope to go from\n                        0 to it's maximum value.",
				"name": "attack"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The period of time after the attack that it takes for the envelope\n                      \tto fall to the sustain value.",
				"name": "decay"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The percent of the maximum value that the envelope rests at until\n                               \tthe release is triggered.",
				"name": "sustain"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The amount of time after the release is triggered it takes to reach 0.",
				"name": "release"
			}
		],
		"examples": [
			"//an amplitude envelope\nvar gainNode = Tone.context.createGain();\nvar env = new Tone.Envelope({\n\t\"attack\" : 0.1,\n\t\"decay\" : 0.2,\n\t\"sustain\" : 1,\n\t\"release\" : 0.8,\n});\nenv.connect(gainNode.gain);"
		],
		"extends": "Tone.AudioNode"
	},
	"Follower": {
		"description": "Tone.Follower is a  crude envelope follower which will follow\n         the amplitude of an incoming signal.\n         Take care with small (< 0.02) attack or decay values\n         as follower has some ripple which is exaggerated\n         at these values. Read more about envelope followers (also known\n         as envelope detectors) on [Wikipedia](https://en.wikipedia.org/wiki/Envelope_detector).",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "The rate at which the follower rises.",
				"name": "attack"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The rate at which the folower falls.",
				"name": "release"
			}
		],
		"examples": [
			"var follower = new Tone.Follower(0.2, 0.4);"
		],
		"extends": "Tone.AudioNode"
	},
	"FrequencyEnvelope": {
		"description": "Tone.FrequencyEnvelope is a Tone.ScaledEnvelope, but instead of `min` and `max`\n        it's got a `baseFrequency` and `octaves` parameter.",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "the attack time in seconds",
				"name": "attack"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "the decay time in seconds",
				"name": "decay"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "a percentage (0-1) of the full amplitude",
				"name": "sustain"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "the release time in seconds",
				"name": "release"
			}
		],
		"examples": [
			"var env = new Tone.FrequencyEnvelope({\n \t\"attack\" : 0.2,\n \t\"baseFrequency\" : \"C2\",\n \t\"octaves\" : 4\n });\n scaledEnv.connect(oscillator.frequency);"
		],
		"extends": "Tone.Envelope"
	},
	"LFO": {
		"description": "LFO stands for low frequency oscillator. Tone.LFO produces an output signal\n         which can be attached to an AudioParam or Tone.Signal\n         in order to modulate that parameter with an oscillator. The LFO can\n         also be synced to the transport to start/stop and change when the tempo changes.",
		"params": [
			{
				"type": [
					"Frequency",
					"Object"
				],
				"optional": true,
				"description": "The frequency of the oscillation. Typically, LFOs will be\n                              in the frequency range of 0.1 to 10 hertz.",
				"name": "frequency"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "The minimum output value of the LFO.",
				"name": "min"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "The maximum value of the LFO.",
				"name": "max"
			}
		],
		"examples": [
			"var lfo = new Tone.LFO(\"4n\", 400, 4000);\nlfo.connect(filter.frequency);"
		],
		"extends": "Tone.AudioNode"
	},
	"MidSideMerge": {
		"description": "Mid/Side processing separates the the 'mid' signal\n        (which comes out of both the left and the right channel)\n        and the 'side' (which only comes out of the the side channels).\n        MidSideMerge merges the mid and side signal after they've been seperated\n        by Tone.MidSideSplit.<br><br>\n        <code>\n        Left = (Mid+Side)/sqrt(2);   // obtain left signal from mid and side<br>\n        Right = (Mid-Side)/sqrt(2);   // obtain right signal from mid and side<br>\n        </code>",
		"extends": "Tone.AudioNode"
	},
	"MidSideSplit": {
		"description": "Mid/Side processing separates the the 'mid' signal\n        (which comes out of both the left and the right channel)\n        and the 'side' (which only comes out of the the side channels). <br><br>\n        <code>\n        Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right<br>\n        Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and righ<br>\n        </code>",
		"extends": "Tone.AudioNode"
	},
	"Panner": {
		"description": "Tone.Panner is an equal power Left/Right Panner and does not\n         support 3D. Panner uses the StereoPannerNode when available.",
		"params": [
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"defaultvalue": 0,
				"description": "The initail panner value (center).",
				"name": "initialPan"
			}
		],
		"examples": [
			"//pan the input signal hard right.\n var panner = new Tone.Panner(1);"
		],
		"extends": "Tone.AudioNode"
	},
	"Panner3D": {
		"description": "A spatialized panner node which supports equalpower or HRTF panning.\n         Tries to normalize the API across various browsers. See Tone.Listener",
		"params": [
			{
				"type": [
					"Number"
				],
				"description": "The initial x position.",
				"name": "positionX"
			},
			{
				"type": [
					"Number"
				],
				"description": "The initial y position.",
				"name": "positionY"
			},
			{
				"type": [
					"Number"
				],
				"description": "The initial z position.",
				"name": "positionZ"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"ScaledEnvelope": {
		"description": "Tone.ScaledEnvelop is an envelope which can be scaled \n        to any range. It's useful for applying an envelope \n        to a frequency or any other non-NormalRange signal \n        parameter.",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "the attack time in seconds",
				"name": "attack"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "the decay time in seconds",
				"name": "decay"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "a percentage (0-1) of the full amplitude",
				"name": "sustain"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "the release time in seconds",
				"name": "release"
			}
		],
		"examples": [
			"var scaledEnv = new Tone.ScaledEnvelope({\n \t\"attack\" : 0.2,\n \t\"min\" : 200,\n \t\"max\" : 2000\n });\n scaledEnv.connect(oscillator.frequency);"
		],
		"extends": "Tone.Envelope"
	},
	"Solo": {
		"description": "Tone.Solo lets you isolate a specific audio stream. When\n        an instance is set to `solo=true`, it will mute all other instances.",
		"examples": [
			"var soloA = new Tone.Solo()\nvar soloB = new Tone.Solo()\nsoloA.solo = true\n//no audio will pass through soloB"
		],
		"extends": "Tone.AudioNode"
	},
	"CtrlInterpolate": {
		"description": "Tone.CtrlInterpolate will interpolate between given values based\n        on the \"index\" property. Passing in an array or object literal\n        will interpolate each of the parameters. Note (i.e. \"C3\")\n        and Time (i.e. \"4n + 2\") can be interpolated. All other values are\n        assumed to be numbers.",
		"params": [
			{
				"type": [
					"Array"
				],
				"description": "The array of values to interpolate over",
				"name": "values"
			},
			{
				"type": [
					"Positive"
				],
				"description": "The initial interpolation index.",
				"name": "index"
			}
		],
		"examples": [
			"var interp = new Tone.CtrlInterpolate([0, 2, 9, 4]);\ninterp.index = 0.75;\ninterp.value; //returns 1.5\n\n ",
			"var interp = new Tone.CtrlInterpolate([\n\t[2, 4, 5],\n\t[9, 3, 2],\n]);"
		],
		"extends": "Tone"
	},
	"CtrlMarkov": {
		"description": "Tone.CtrlMarkov represents a Markov Chain where each call\n        to Tone.CtrlMarkov.next will move to the next state. If the next\n        state choice is an array, the next state is chosen randomly with\n        even probability for all of the choices. For a weighted probability\n        of the next choices, pass in an object with \"state\" and \"probability\" attributes. \n        The probabilities will be normalized and then chosen. If no next options\n        are given for the current state, the state will stay there.",
		"params": [
			{
				"type": [
					"Object"
				],
				"description": "An object with the state names as the keys\n                        and the next state(s) as the values.",
				"name": "values"
			}
		],
		"examples": [
			"var chain = new Tone.CtrlMarkov({\n\t\"beginning\" : [\"end\", \"middle\"],\n\t\"middle\" : \"end\"\n});\nchain.value = \"beginning\";\nchain.next(); //returns \"end\" or \"middle\" with 50% probability\n\n ",
			"var chain = new Tone.CtrlMarkov({\n\t\"beginning\" : [{\"value\" : \"end\", \"probability\" : 0.8}, \n\t\t\t\t\t{\"value\" : \"middle\", \"probability\" : 0.2}],\n\t\"middle\" : \"end\"\n});\nchain.value = \"beginning\";\nchain.next(); //returns \"end\" with 80% probability or \"middle\" with 20%.\n "
		],
		"extends": "Tone"
	},
	"CtrlPattern": {
		"description": "Generate patterns from an array of values.\n        Has a number of arpeggiation and randomized\n        selection patterns. \n          <ul>\n \t        <li>\"up\" - cycles upward</li>\n \t\t\t<li>\"down\" - cycles downward</li>\n \t\t\t<li>\"upDown\" - up then and down</li>\n \t\t\t<li>\"downUp\" - cycles down then and up</li>\n \t\t\t<li>\"alternateUp\" - jump up two and down one</li>\n \t\t\t<li>\"alternateDown\" - jump down two and up one</li>\n \t\t\t<li>\"random\" - randomly select an index</li>\n \t\t\t<li>\"randomWalk\" - randomly moves one index away from the current position</li>\n \t\t\t<li>\"randomOnce\" - randomly select an index without repeating until all values have been chosen.</li>\n    \t\t</ul>",
		"params": [
			{
				"type": [
					"Array"
				],
				"description": "An array of options to choose from.",
				"name": "values"
			},
			{
				"type": [
					"Tone.CtrlPattern.Type"
				],
				"optional": true,
				"description": "The name of the pattern.",
				"name": "type"
			}
		],
		"extends": "Tone"
	},
	"CtrlRandom": {
		"description": "Choose a random value.",
		"params": [
			{
				"type": [
					"Number",
					"Time"
				],
				"description": "The minimum return value.",
				"name": "min"
			},
			{
				"type": [
					"Number",
					"Time"
				],
				"description": "The maximum return value.",
				"name": "max"
			}
		],
		"examples": [
			"var randomWalk = new Tone.CtrlRandom({\n\t\"min\" : 0,\n\t\"max\" : 10,\n\t\"integer\" : true\n});\nrandomWalk.eval();\n\n "
		],
		"extends": "Tone"
	},
	"Master": {
		"description": "A single master output which is connected to the\n         AudioDestinationNode (aka your speakers).\n         It provides useful conveniences such as the ability\n         to set the volume and mute the entire application.\n         It also gives you the ability to apply master effects to your application.\n         <br><br>\n         Like Tone.Transport, A single Tone.Master is created\n         on initialization and you do not need to explicitly construct one.",
		"examples": [
			"//the audio will go from the oscillator to the speakers\noscillator.connect(Tone.Master);\n//a convenience for connecting to the master output is also provided:\noscillator.toMaster();\n//the above two examples are equivalent."
		],
		"singleton": true,
		"extends": "Tone"
	},
	"AudioNode": {
		"description": "Tone.AudioNode is the base class for classes which process audio.\n        AudioNodes have inputs and outputs.",
		"params": [
			{
				"type": [
					"AudioContext"
				],
				"optional": true,
				"description": "The audio context to use with the class",
				"name": "context"
			}
		],
		"extends": "Tone"
	},
	"Buffer": {
		"description": "Buffer loading and storage. Tone.Buffer is used internally by all \n         classes that make requests for audio files such as Tone.Player,\n         Tone.Sampler and Tone.Convolver.\n         \n         Aside from load callbacks from individual buffers, Tone.Buffer \n \t\tprovides events which keep track of the loading progress \n \t\tof _all_ of the buffers. These are Tone.Buffer.on(\"load\" / \"progress\" / \"error\")",
		"params": [
			{
				"type": [
					"AudioBuffer",
					"String"
				],
				"description": "The url to load, or the audio buffer to set.",
				"name": "url"
			},
			{
				"type": [
					"function"
				],
				"optional": true,
				"description": "A callback which is invoked after the buffer is loaded. \n                           It's recommended to use `Tone.Buffer.on('load', callback)` instead \n                           since it will give you a callback when _all_ buffers are loaded.",
				"name": "onload"
			},
			{
				"type": [
					"function"
				],
				"optional": true,
				"description": "The callback to invoke if there is an error",
				"name": "onerror"
			}
		],
		"examples": [
			"var buffer = new Tone.Buffer(\"path/to/sound.mp3\", function(){\n\t//the buffer is now available.\n\tvar buff = buffer.get();\n});\n ",
			"//can load provide fallback extension types if the first type is not supported.\nvar buffer = new Tone.Buffer(\"path/to/sound.[mp3|ogg|wav]\");"
		],
		"extends": "Tone"
	},
	"Buffers": {
		"description": "A data structure for holding multiple buffers.",
		"params": [
			{
				"type": [
					"Object",
					"Array"
				],
				"description": "An object literal or array\n                                     of urls to load.",
				"name": "urls"
			},
			{
				"type": [
					"function"
				],
				"optional": true,
				"description": "The callback to invoke when\n                                the buffers are loaded.",
				"name": "callback"
			}
		],
		"examples": [
			"//load a whole bank of piano samples\nvar pianoSamples = new Tone.Buffers({\n\t\"C4\" : \"path/to/C4.mp3\"\n\t\"C#4\" : \"path/to/C#4.mp3\"\n\t\"D4\" : \"path/to/D4.mp3\"\n\t\"D#4\" : \"path/to/D#4.mp3\"\n\t...\n}, function(){\n\t//play one of the samples when they all load\n\tplayer.buffer = pianoSamples.get(\"C4\");\n\tplayer.start();\n});\n\t",
			"//To pass in additional parameters in the second parameter\nvar buffers = new Tone.Buffers(urls, {\n\t\"onload\" : callback,\n\t\"baseUrl\" : \"../path/to/audio/\"\n})"
		],
		"extends": "Tone"
	},
	"Clock": {
		"description": "A sample accurate clock which provides a callback at the given rate. \n         While the callback is not sample-accurate (it is still susceptible to\n         loose JS timing), the time passed in as the argument to the callback\n         is precise. For most applications, it is better to use Tone.Transport\n         instead of the Clock by itself since you can synchronize multiple callbacks.",
		"params": [
			{
				"type": [
					"function"
				],
				"description": "The callback to be invoked with the time of the audio event",
				"name": "callback"
			},
			{
				"type": [
					"Frequency"
				],
				"description": "The rate of the callback",
				"name": "frequency"
			}
		],
		"examples": [
			"//the callback will be invoked approximately once a second\n//and will print the time exactly once a second apart.\nvar clock = new Tone.Clock(function(time){\n\tconsole.log(time);\n}, 1);"
		],
		"extends": "Tone.Emitter"
	},
	"Context": {
		"description": "Wrapper around the native AudioContext.",
		"params": [
			{
				"type": [
					"AudioContext"
				],
				"optional": true,
				"description": "optionally pass in a context",
				"name": "context"
			}
		],
		"extends": "Tone.Emitter"
	},
	"Delay": {
		"description": "Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).",
		"params": [
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The delay applied to the incoming signal.",
				"name": "delayTime"
			},
			{
				"type": [
					"Time"
				],
				"optional": true,
				"description": "The maximum delay time.",
				"name": "maxDelay"
			}
		],
		"extends": "Tone"
	},
	"Draw": {
		"description": "Tone.Draw is useful for synchronizing visuals and audio events.\n        Callbacks from Tone.Transport or any of the Tone.Event classes\n        always happen _before_ the scheduled time and are not synchronized\n        to the animation frame so they are not good for triggering tightly\n        synchronized visuals and sound. Tone.Draw makes it easy to schedule\n        callbacks using the AudioContext time and uses requestAnimationFrame.",
		"examples": [
			"Tone.Transport.schedule(function(time){\n\t//use the time argument to schedule a callback with Tone.Draw\n\tTone.Draw.schedule(function(){\n\t\t//do drawing or DOM manipulation here\n\t}, time)\n}, \"+0.5\")"
		],
		"singleton": true,
		"extends": "Tone"
	},
	"Emitter": {
		"description": "Tone.Emitter gives classes which extend it\n        the ability to listen for and emit events. \n        Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).\n        MIT (c) 2011 Jerome Etienne.",
		"extends": "Tone"
	},
	"Gain": {
		"description": "A thin wrapper around the Native Web Audio GainNode.\n        The GainNode is a basic building block of the Web Audio\n        API and is useful for routing audio and adjusting gains.",
		"params": [
			{
				"type": [
					"Number"
				],
				"optional": true,
				"description": "The initial gain of the GainNode",
				"name": "gain"
			},
			{
				"type": [
					"Tone.Type"
				],
				"optional": true,
				"description": "The units of the gain parameter.",
				"name": "units"
			}
		],
		"extends": "Tone"
	},
	"IntervalTimeline": {
		"description": "Similar to Tone.Timeline, but all events represent\n        intervals with both \"time\" and \"duration\" times. The \n        events are placed in a tree structure optimized\n        for querying an intersection point with the timeline\n        events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)\n        to represent the data.",
		"extends": "Tone"
	},
	"Listener": {
		"description": "Both Tone.Panner3D and Tone.Listener have a position in 3D space \n         using a right-handed cartesian coordinate system. \n         The units used in the coordinate system are not defined; \n         these coordinates are independent/invariant of any particular \n         units such as meters or feet. Tone.Panner3D objects have an forward \n         vector representing the direction the sound is projecting. Additionally, \n         they have a sound cone representing how directional the sound is. \n         For example, the sound could be omnidirectional, in which case it would \n         be heard anywhere regardless of its forward, or it can be more directional \n         and heard only if it is facing the listener. Tone.Listener objects \n         (representing a person's ears) have an forward and up vector \n         representing in which direction the person is facing. Because both the \n         source stream and the listener can be moving, they both have a velocity \n         vector representing both the speed and direction of movement. Taken together, \n         these two velocities can be used to generate a doppler shift effect which changes the pitch.\n         <br><br>\n         Note: the position of the Listener will have no effect on nodes not connected to a Tone.Panner3D",
		"singleton": true,
		"extends": "Tone"
	},
	"OfflineContext": {
		"description": "Wrapper around the OfflineAudioContext",
		"params": [
			{
				"type": [
					"Number"
				],
				"description": "The number of channels to render",
				"name": "channels"
			},
			{
				"type": [
					"Number"
				],
				"description": "The duration to render in samples",
				"name": "duration"
			},
			{
				"type": [
					"Number"
				],
				"description": "the sample rate to render at",
				"name": "sampleRate"
			}
		],
		"extends": "Tone.Context"
	},
	"Param": {
		"description": "Tone.Param wraps the native Web Audio's AudioParam to provide\n        additional unit conversion functionality. It also\n        serves as a base-class for classes which have a single,\n        automatable parameter.",
		"params": [
			{
				"type": [
					"AudioParam"
				],
				"description": "The parameter to wrap.",
				"name": "param"
			},
			{
				"type": [
					"Tone.Type"
				],
				"description": "The units of the audio param.",
				"name": "units"
			},
			{
				"type": [
					"Boolean"
				],
				"description": "If the param should be converted.",
				"name": "convert"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"Timeline": {
		"description": "A Timeline class for scheduling and maintaining state\n        along a timeline. All events must have a \"time\" property.\n        Internally, events are stored in time order for fast\n        retrieval.",
		"params": [
			{
				"type": [
					"Positive"
				],
				"optional": true,
				"defaultvalue": "Infinity",
				"description": "The number of previous events that are retained.",
				"name": "memory"
			}
		],
		"extends": "Tone"
	},
	"TimelineState": {
		"description": "A Timeline State. Provides the methods: <code>setStateAtTime(\"state\", time)</code>\n         and <code>getValueAtTime(time)</code>.",
		"params": [
			{
				"type": [
					"String"
				],
				"description": "The initial state of the TimelineState. \n                         Defaults to <code>undefined</code>",
				"name": "initial"
			}
		],
		"extends": "Tone.Timeline"
	},
	"Tone": {
		"description": "Tone is the base class of all other classes.",
		"params": []
	},
	"Transport": {
		"description": "Transport for timing musical events.\n         Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)\n         Tone.Transport timing events pass in the exact time of the scheduled event\n         in the argument of the callback function. Pass that time value to the object\n         you're scheduling. <br><br>\n         A single transport is created for you when the library is initialized.\n         <br><br>\n         The transport emits the events: \"start\", \"stop\", \"pause\", and \"loop\" which are\n         called with the time of that event as the argument.",
		"examples": [
			"//repeated event every 8th note\nTone.Transport.scheduleRepeat(function(time){\n\t//do something with the time\n}, \"8n\");\n ",
			"//schedule an event on the 16th measure\nTone.Transport.schedule(function(time){\n\t//do something with the time\n}, \"16:0:0\");"
		],
		"singleton": true,
		"extends": "Tone.Emitter"
	},
	"TransportEvent": {
		"description": "Tone.TransportEvent is an internal class used by (Tone.Transport)[Transport]\n        to schedule events. Do no invoke this class directly, it is\n        handled from within Tone.Transport.",
		"params": [
			{
				"type": [
					"Object"
				],
				"name": "options"
			}
		],
		"extends": "Tone"
	},
	"TransportRepeatEvent": {
		"description": "Tone.TransportRepeatEvent is an internal class used by Tone.Transport\n        to schedule repeat events. This class should not be instantiated directly.",
		"params": [
			{
				"type": [
					"Object"
				],
				"name": "options"
			}
		],
		"extends": "Tone.TransportEvent"
	},
	"AutoFilter": {
		"description": "Tone.AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.\n        Setting the LFO rate and depth allows for control over the filter modulation rate \n        and depth.",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "The rate of the LFO.",
				"name": "frequency"
			},
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "The lower value of the LFOs oscillation",
				"name": "baseFrequency"
			},
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "The number of octaves above the baseFrequency",
				"name": "octaves"
			}
		],
		"examples": [
			"//create an autofilter and start it's LFO\nvar autoFilter = new Tone.AutoFilter(\"4n\").toMaster().start();\n//route an oscillator through the filter and start it\nvar oscillator = new Tone.Oscillator().connect(autoFilter).start();"
		],
		"extends": "Tone.Effect"
	},
	"Effect": {
		"description": "Tone.Effect is the base class for effects. Connect the effect between\n\t        the effectSend and effectReturn GainNodes, then control the amount of\n\t        effect which goes to the output using the wet control.",
		"params": [
			{
				"type": [
					"NormalRange",
					"Object"
				],
				"optional": true,
				"description": "The starting wet value.",
				"name": "wet"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"FeedbackEffect": {
		"description": "Tone.FeedbackEffect provides a loop between an \n\t        audio source and its own output. This is a base-class\n\t        for feedback effects.",
		"params": [
			{
				"type": [
					"NormalRange",
					"Object"
				],
				"optional": true,
				"description": "The initial feedback value.",
				"name": "feedback"
			}
		],
		"extends": "Tone.Effect"
	},
	"AutoPanner": {
		"description": "Tone.AutoPanner is a Tone.Panner with an LFO connected to the pan amount. \n        More on using autopanners [here](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).",
		"params": [
			{
				"type": [
					"Frequency",
					"Object"
				],
				"optional": true,
				"description": "Rate of left-right oscillation.",
				"name": "frequency"
			}
		],
		"examples": [
			"//create an autopanner and start it's LFO\nvar autoPanner = new Tone.AutoPanner(\"4n\").toMaster().start();\n//route an oscillator through the panner and start it\nvar oscillator = new Tone.Oscillator().connect(autoPanner).start();"
		],
		"extends": "Tone.Effect"
	},
	"AutoWah": {
		"description": "Tone.AutoWah connects a Tone.Follower to a bandpass filter (Tone.Filter).\n         The frequency of the filter is adjusted proportionally to the \n         incoming signal's amplitude. Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).",
		"params": [
			{
				"type": [
					"Frequency",
					"Object"
				],
				"optional": true,
				"description": "The frequency the filter is set \n                                           to at the low point of the wah",
				"name": "baseFrequency"
			},
			{
				"type": [
					"Positive"
				],
				"optional": true,
				"description": "The number of octaves above the baseFrequency\n                               the filter will sweep to when fully open",
				"name": "octaves"
			},
			{
				"type": [
					"Decibels"
				],
				"optional": true,
				"description": "The decibel threshold sensitivity for \n                                  the incoming signal. Normal range of -40 to 0.",
				"name": "sensitivity"
			}
		],
		"examples": [
			"var autoWah = new Tone.AutoWah(50, 6, -30).toMaster();\n//initialize the synth and connect to autowah\nvar synth = new Synth.connect(autoWah);\n//Q value influences the effect of the wah - default is 2\nautoWah.Q.value = 6;\n//more audible on higher notes\nsynth.triggerAttackRelease(\"C4\", \"8n\")"
		],
		"extends": "Tone.Effect"
	},
	"BitCrusher": {
		"description": "Tone.Bitcrusher downsamples the incoming signal to a different bitdepth. \n        Lowering the bitdepth of the signal creates distortion. Read more about Bitcrushing\n        on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).",
		"params": [
			{
				"type": [
					"Number"
				],
				"description": "The number of bits to downsample the signal. Nominal range\n                      of 1 to 8.",
				"name": "bits"
			}
		],
		"examples": [
			"//initialize crusher and route a synth through it\nvar crusher = new Tone.BitCrusher(4).toMaster();\nvar synth = new Tone.MonoSynth().connect(crusher);"
		],
		"extends": "Tone.Effect"
	},
	"Chebyshev": {
		"description": "Tone.ChebyShev is a Chebyshev waveshaper, an effect which is good \n        for making different types of distortion sounds.\n        Note that odd orders sound very different from even ones, \n        and order = 1 is no change. \n        Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).",
		"params": [
			{
				"type": [
					"Positive",
					"Object"
				],
				"optional": true,
				"description": "The order of the chebyshev polynomial. Normal range between 1-100.",
				"name": "order"
			}
		],
		"examples": [
			"//create a new cheby\nvar cheby = new Tone.Chebyshev(50);\n//create a monosynth connected to our cheby\nsynth = new Tone.MonoSynth().connect(cheby);"
		],
		"extends": "Tone.Effect"
	},
	"Chorus": {
		"description": "Tone.Chorus is a stereo chorus effect with feedback composed of \n        a left and right delay with a Tone.LFO applied to the delayTime of each channel. \n        Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).\n        Read more on the chorus effect on [SoundOnSound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).",
		"params": [
			{
				"type": [
					"Frequency",
					"Object"
				],
				"optional": true,
				"description": "The frequency of the LFO.",
				"name": "frequency"
			},
			{
				"type": [
					"Milliseconds"
				],
				"optional": true,
				"description": "The delay of the chorus effect in ms.",
				"name": "delayTime"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The depth of the chorus.",
				"name": "depth"
			}
		],
		"examples": [
			"var chorus = new Tone.Chorus(4, 2.5, 0.5);\nvar synth = new Tone.PolySynth(4, Tone.MonoSynth).connect(chorus);\nsynth.triggerAttackRelease([\"C3\",\"E3\",\"G3\"], \"8n\");"
		],
		"extends": "Tone.StereoXFeedbackEffect"
	},
	"Convolver": {
		"description": "Tone.Convolver is a wrapper around the Native Web Audio \n         [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).\n         Convolution is useful for reverb and filter emulation. Read more about convolution reverb on\n         [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).",
		"params": [
			{
				"type": [
					"string",
					"Tone.Buffer",
					"Object"
				],
				"optional": true,
				"description": "The URL of the impulse response or the Tone.Buffer\n                                          contianing the impulse response.",
				"name": "url"
			},
			{
				"type": [
					"function"
				],
				"description": "The callback to invoke when the url is loaded.",
				"name": "onload"
			}
		],
		"examples": [
			"//initializing the convolver with an impulse response\nvar convolver = new Tone.Convolver(\"./path/to/ir.wav\").toMaster();"
		],
		"extends": "Tone.Effect"
	},
	"Distortion": {
		"description": "Tone.Distortion is a simple distortion effect using Tone.WaveShaper.\n        Algorithm from [a stackoverflow answer](http://stackoverflow.com/a/22313408).",
		"params": [
			{
				"type": [
					"Number",
					"Object"
				],
				"optional": true,
				"description": "The amount of distortion (nominal range of 0-1)",
				"name": "distortion"
			}
		],
		"examples": [
			"var dist = new Tone.Distortion(0.8).toMaster();\nvar fm = new Tone.SimpleFM().connect(dist);\n//this sounds good on bass notes\nfm.triggerAttackRelease(\"A1\", \"8n\");"
		],
		"extends": "Tone.Effect"
	},
	"FeedbackDelay": {
		"description": "Tone.FeedbackDelay is a DelayNode in which part of output\n         signal is fed back into the delay.",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "The delay applied to the incoming signal.",
				"name": "delayTime"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The amount of the effected signal which \n                           is fed back through the delay.",
				"name": "feedback"
			}
		],
		"examples": [
			"var feedbackDelay = new Tone.FeedbackDelay(\"8n\", 0.5).toMaster();\nvar tom = new Tone.DrumSynth({\n\t\"octaves\" : 4,\n\t\"pitchDecay\" : 0.1\n}).connect(feedbackDelay);\ntom.triggerAttackRelease(\"A2\",\"32n\");"
		],
		"extends": "Tone.FeedbackEffect"
	},
	"Freeverb": {
		"description": "Tone.Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).\n        Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).",
		"params": [
			{
				"type": [
					"NormalRange",
					"Object"
				],
				"optional": true,
				"description": "Correlated to the decay time.",
				"name": "roomSize"
			},
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "The cutoff frequency of a lowpass filter as part\n                                of the reverb.",
				"name": "dampening"
			}
		],
		"examples": [
			"var freeverb = new Tone.Freeverb().toMaster();\nfreeverb.dampening.value = 1000;\n//routing synth through the reverb\nvar synth = new Tone.AMSynth().connect(freeverb);"
		],
		"extends": "Tone.Effect"
	},
	"JCReverb": {
		"description": "Tone.JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)\n        tuned by John Chowning in 1970.\n        It is made up of three allpass filters and four Tone.FeedbackCombFilter.",
		"params": [
			{
				"type": [
					"NormalRange",
					"Object"
				],
				"optional": true,
				"description": "Coorelates to the decay time.",
				"name": "roomSize"
			}
		],
		"examples": [
			"var reverb = new Tone.JCReverb(0.4).connect(Tone.Master);\nvar delay = new Tone.FeedbackDelay(0.5); \n//connecting the synth to reverb through delay\nvar synth = new Tone.DuoSynth().chain(delay, reverb);\nsynth.triggerAttackRelease(\"A4\",\"8n\");"
		],
		"extends": "Tone.Effect"
	},
	"MidSideEffect": {
		"description": "Mid/Side processing separates the the 'mid' signal \n        (which comes out of both the left and the right channel) \n        and the 'side' (which only comes out of the the side channels) \n        and effects them separately before being recombined.\n        Applies a Mid/Side seperation and recombination.\n        Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n        <br><br>\n        This is a base-class for Mid/Side Effects.",
		"extends": "Tone.Effect"
	},
	"Phaser": {
		"description": "Tone.Phaser is a phaser effect. Phasers work by changing the phase\n        of different frequency components of an incoming signal. Read more on \n        [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)). \n        Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).",
		"params": [
			{
				"type": [
					"Frequency",
					"Object"
				],
				"optional": true,
				"description": "The speed of the phasing.",
				"name": "frequency"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "The octaves of the effect.",
				"name": "octaves"
			},
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "The base frequency of the filters.",
				"name": "baseFrequency"
			}
		],
		"examples": [
			"var phaser = new Tone.Phaser({\n\t\"frequency\" : 15, \n\t\"octaves\" : 5, \n\t\"baseFrequency\" : 1000\n}).toMaster();\nvar synth = new Tone.FMSynth().connect(phaser);\nsynth.triggerAttackRelease(\"E3\", \"2n\");"
		],
		"extends": "Tone.StereoEffect"
	},
	"PingPongDelay": {
		"description": "Tone.PingPongDelay is a feedback delay effect where the echo is heard\n         first in one channel and next in the opposite channel. In a stereo\n         system these are the right and left channels.\n         PingPongDelay in more simplified terms is two Tone.FeedbackDelays \n         with independent delay values. Each delay is routed to one channel\n         (left or right), and the channel triggered second will always \n         trigger at the same interval after the first.",
		"params": [
			{
				"type": [
					"Time",
					"Object"
				],
				"optional": true,
				"description": "The delayTime between consecutive echos.",
				"name": "delayTime"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The amount of the effected signal which \n                                is fed back through the delay.",
				"name": "feedback"
			}
		],
		"examples": [
			"var pingPong = new Tone.PingPongDelay(\"4n\", 0.2).toMaster();\nvar drum = new Tone.DrumSynth().connect(pingPong);\ndrum.triggerAttackRelease(\"C4\", \"32n\");"
		],
		"extends": "Tone.StereoXFeedbackEffect"
	},
	"PitchShift": {
		"description": "Tone.PitchShift does near-realtime pitch shifting to the incoming signal. \n        The effect is achieved by speeding up or slowing down the delayTime\n        of a DelayNode using a sawtooth wave. \n        Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).\n        Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).",
		"params": [
			{
				"type": [
					"Interval"
				],
				"optional": true,
				"description": "The interval to transpose the incoming signal by.",
				"name": "pitch"
			}
		],
		"extends": "Tone.FeedbackEffect"
	},
	"StereoEffect": {
		"description": "Base class for Stereo effects. Provides effectSendL/R and effectReturnL/R.",
		"extends": "Tone.Effect"
	},
	"StereoFeedbackEffect": {
		"description": "Base class for stereo feedback effects where the effectReturn\n        is fed back into the same channel.",
		"extends": "Tone.StereoEffect"
	},
	"StereoWidener": {
		"description": "Applies a width factor to the mid/side seperation. \n        0 is all mid and 1 is all side.\n        Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n        <br><br>\n        <code>\n        Mid *= 2*(1-width)<br>\n        Side *= 2*width\n        </code>",
		"params": [
			{
				"type": [
					"NormalRange",
					"Object"
				],
				"optional": true,
				"description": "The stereo width. A width of 0 is mono and 1 is stereo. 0.5 is no change.",
				"name": "width"
			}
		],
		"extends": "Tone.MidSideEffect"
	},
	"StereoXFeedbackEffect": {
		"description": "Just like a stereo feedback effect, but the feedback is routed from left to right\n        and right to left instead of on the same channel.",
		"extends": "Tone.StereoEffect"
	},
	"Tremolo": {
		"description": "Tone.Tremolo modulates the amplitude of an incoming signal using a Tone.LFO.\n        The type, frequency, and depth of the LFO is controllable.",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "The rate of the effect.",
				"name": "frequency"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The depth of the effect.",
				"name": "depth"
			}
		],
		"examples": [
			"//create a tremolo and start it's LFO\nvar tremolo = new Tone.Tremolo(9, 0.75).toMaster().start();\n//route an oscillator through the tremolo and start it\nvar oscillator = new Tone.Oscillator().connect(tremolo).start();"
		],
		"extends": "Tone.StereoEffect"
	},
	"Vibrato": {
		"description": "A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO\n        modulates the delayTime of the delay, causing the pitch to rise\n        and fall.",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"description": "The frequency of the vibrato.",
				"name": "frequency"
			},
			{
				"type": [
					"NormalRange"
				],
				"description": "The amount the pitch is modulated.",
				"name": "depth"
			}
		],
		"extends": "Tone.Effect"
	},
	"Event": {
		"description": "Tone.Event abstracts away Tone.Transport.schedule and provides a schedulable\n         callback for a single or repeatable events along the timeline.",
		"params": [
			{
				"type": [
					"function"
				],
				"description": "The callback to invoke at the time.",
				"name": "callback"
			},
			{
				"type": [
					"*"
				],
				"description": "The value or values which should be passed to\n                     the callback function on invocation.",
				"name": "value"
			}
		],
		"examples": [
			"var chord = new Tone.Event(function(time, chord){\n\t//the chord as well as the exact time of the event\n\t//are passed in as arguments to the callback function\n}, [\"D4\", \"E4\", \"F4\"]);\n//start the chord at the beginning of the transport timeline\nchord.start();\n//loop it every measure for 8 measures\nchord.loop = 8;\nchord.loopEnd = \"1m\";"
		],
		"extends": "Tone"
	},
	"Loop": {
		"description": "Tone.Loop creates a looped callback at the \n        specified interval. The callback can be \n        started, stopped and scheduled along\n        the Transport's timeline.",
		"params": [
			{
				"type": [
					"function"
				],
				"description": "The callback to invoke with the event.",
				"name": "callback"
			},
			{
				"type": [
					"Time"
				],
				"description": "The time between successive callback calls.",
				"name": "interval"
			}
		],
		"examples": [
			"var loop = new Tone.Loop(function(time){\n\t//triggered every eighth note. \n\tconsole.log(time);\n}, \"8n\").start(0);\nTone.Transport.start();\n "
		],
		"extends": "Tone"
	},
	"Part": {
		"description": "Tone.Part is a collection Tone.Events which can be\n        started/stopped and looped as a single unit.",
		"params": [
			{
				"type": [
					"function"
				],
				"description": "The callback to invoke on each event",
				"name": "callback"
			},
			{
				"type": [
					"Array"
				],
				"description": "the array of events",
				"name": "events"
			}
		],
		"examples": [
			"var part = new Tone.Part(function(time, note){\n\t//the notes given as the second element in the array\n\t//will be passed in as the second argument\n\tsynth.triggerAttackRelease(note, \"8n\", time);\n}, [[0, \"C2\"], [\"0:2\", \"C3\"], [\"0:3:2\", \"G2\"]]);\n ",
			"//use an array of objects as long as the object has a \"time\" attribute\nvar part = new Tone.Part(function(time, value){\n\t//the value is an object which contains both the note and the velocity\n\tsynth.triggerAttackRelease(value.note, \"8n\", time, value.velocity);\n}, [{\"time\" : 0, \"note\" : \"C3\", \"velocity\": 0.9}, \n\t   {\"time\" : \"0:2\", \"note\" : \"C4\", \"velocity\": 0.5}\n]).start(0);"
		],
		"extends": "Tone.Event"
	},
	"Pattern": {
		"description": "Tone.Pattern arpeggiates between the given notes\n        in a number of patterns. See Tone.CtrlPattern for\n        a full list of patterns.",
		"params": [
			{
				"type": [
					"function"
				],
				"description": "The callback to invoke with the\n                            event.",
				"name": "callback"
			},
			{
				"type": [
					"Array"
				],
				"description": "The values to arpeggiate over.",
				"name": "values"
			}
		],
		"examples": [
			"var pattern = new Tone.Pattern(function(time, note){\n  //the order of the notes passed in depends on the pattern\n}, [\"C2\", \"D4\", \"E5\", \"A6\"], \"upDown\");\n "
		],
		"extends": "Tone.Loop"
	},
	"Sequence": {
		"description": "A sequence is an alternate notation of a part. Instead\n        of passing in an array of [time, event] pairs, pass\n        in an array of events which will be spaced at the\n        given subdivision. Sub-arrays will subdivide that beat\n        by the number of items are in the array. \n        Sequence notation inspiration from [Tidal](http://yaxu.org/tidal/)",
		"params": [
			{
				"type": [
					"function"
				],
				"description": "The callback to invoke with every note",
				"name": "callback"
			},
			{
				"type": [
					"Array"
				],
				"description": "The sequence",
				"name": "events"
			},
			{
				"type": [
					"Time"
				],
				"description": "The subdivision between which events are placed.",
				"name": "subdivision"
			}
		],
		"examples": [
			"var seq = new Tone.Sequence(function(time, note){\n\tconsole.log(note);\n//straight quater notes\n}, [\"C4\", \"E4\", \"G4\", \"A4\"], \"4n\");\n ",
			"var seq = new Tone.Sequence(function(time, note){\n\tconsole.log(note);\n//subdivisions are given as subarrays\n}, [\"C4\", [\"E4\", \"D4\", \"E4\"], \"G4\", [\"A4\", \"G4\"]]);"
		],
		"extends": "Tone.Part"
	},
	"Instrument": {
		"description": "Base-class for all instruments",
		"extends": "Tone.AudioNode"
	},
	"AMSynth": {
		"description": "AMSynth uses the output of one Tone.Synth to modulate the\n         amplitude of another Tone.Synth. The harmonicity (the ratio between\n         the two signals) affects the timbre of the output signal greatly.\n         Read more about Amplitude Modulation Synthesis on\n         [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).\n         <img src=\"https://docs.google.com/drawings/d/1TQu8Ed4iFr1YTLKpB3U1_hur-UwBrh5gdBXc8BxfGKw/pub?w=1009&h=457\">",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "the options available for the synth\n                           see defaults below",
				"name": "options"
			}
		],
		"examples": [
			"var synth = new Tone.AMSynth().toMaster();\nsynth.triggerAttackRelease(\"C4\", \"4n\");"
		],
		"extends": "Tone.Monophonic"
	},
	"DuoSynth": {
		"description": "Tone.DuoSynth is a monophonic synth composed of two \n         MonoSynths run in parallel with control over the \n         frequency ratio between the two voices and vibrato effect.\n         <img src=\"https://docs.google.com/drawings/d/1bL4GXvfRMMlqS7XyBm9CjL9KJPSUKbcdBNpqOlkFLxk/pub?w=1012&h=448\">",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "the options available for the synth \n                         see defaults below",
				"name": "options"
			}
		],
		"examples": [
			"var duoSynth = new Tone.DuoSynth().toMaster();\nduoSynth.triggerAttackRelease(\"C4\", \"2n\");"
		],
		"extends": "Tone.Monophonic"
	},
	"FMSynth": {
		"description": "FMSynth is composed of two Tone.Synths where one Tone.Synth modulates\n         the frequency of a second Tone.Synth. A lot of spectral content \n         can be explored using the modulationIndex parameter. Read more about\n         frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).\n         <img src=\"https://docs.google.com/drawings/d/1h0PUDZXPgi4Ikx6bVT6oncrYPLluFKy7lj53puxj-DM/pub?w=902&h=462\">",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "the options available for the synth\n                         see defaults below",
				"name": "options"
			}
		],
		"examples": [
			"var fmSynth = new Tone.FMSynth().toMaster();\nfmSynth.triggerAttackRelease(\"C5\", \"4n\");"
		],
		"extends": "Tone.Monophonic"
	},
	"MembraneSynth": {
		"description": "Tone.MembraneSynth makes kick and tom sounds using a single oscillator\n         with an amplitude envelope and frequency ramp. A Tone.OmniOscillator\n         is routed through a Tone.AmplitudeEnvelope to the output. The drum\n         quality of the sound comes from the frequency envelope applied\n         during during Tone.MembraneSynth.triggerAttack(note). The frequency\n         envelope starts at <code>note * .octaves</code> and ramps to \n         <code>note</code> over the duration of <code>.pitchDecay</code>.",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "the options available for the synth \n                         see defaults below",
				"name": "options"
			}
		],
		"examples": [
			"var synth = new Tone.MembraneSynth().toMaster();\nsynth.triggerAttackRelease(\"C2\", \"8n\");"
		],
		"extends": "Tone.Instrument"
	},
	"MetalSynth": {
		"description": "A highly inharmonic and spectrally complex source with a highpass filter\n         and amplitude envelope which is good for making metalophone sounds. Based\n         on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).\n         Inspiration from [Sound on Sound](https://web.archive.org/web/20160610143924/https://www.soundonsound.com/sos/jul02/articles/synthsecrets0702.asp).",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "The options availble for the synth\n                            see defaults below",
				"name": "options"
			}
		],
		"extends": "Tone.Instrument"
	},
	"MonoSynth": {
		"description": "Tone.MonoSynth is composed of one oscillator, one filter, and two envelopes.\n         The amplitude of the Tone.Oscillator and the cutoff frequency of the \n         Tone.Filter are controlled by Tone.Envelopes. \n         <img src=\"https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240\">",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "the options available for the synth \n                         see defaults below",
				"name": "options"
			}
		],
		"examples": [
			"var synth = new Tone.MonoSynth({\n\t\"oscillator\" : {\n\t\t\"type\" : \"square\"\n },\n \"envelope\" : {\n \t\"attack\" : 0.1\n }\n}).toMaster();\nsynth.triggerAttackRelease(\"C4\", \"8n\");"
		],
		"extends": "Tone.Monophonic"
	},
	"Monophonic": {
		"description": "This is an abstract base class for other monophonic instruments to \n         extend. IMPORTANT: It does not make any sound on its own and\n         shouldn't be directly instantiated.",
		"extends": "Tone.Instrument"
	},
	"NoiseSynth": {
		"description": "Tone.NoiseSynth is composed of a noise generator (Tone.Noise), one filter (Tone.Filter), \n         and two envelopes (Tone.Envelop). One envelope controls the amplitude\n         of the noise and the other is controls the cutoff frequency of the filter. \n         <img src=\"https://docs.google.com/drawings/d/1rqzuX9rBlhT50MRvD2TKml9bnZhcZmzXF1rf_o7vdnE/pub?w=918&h=242\">",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "the options available for the synth \n                         see defaults below",
				"name": "options"
			}
		],
		"examples": [
			"var noiseSynth = new Tone.NoiseSynth().toMaster();\nnoiseSynth.triggerAttackRelease(\"8n\");"
		],
		"extends": "Tone.Instrument"
	},
	"PluckSynth": {
		"description": "Karplus-String string synthesis. Often out of tune. \n        Will change when the AudioWorkerNode is available across\n        browsers.",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "see the defaults",
				"name": "options"
			}
		],
		"examples": [
			"var plucky = new Tone.PluckSynth().toMaster();\nplucky.triggerAttack(\"C4\");"
		],
		"extends": "Tone.Instrument"
	},
	"PolySynth": {
		"description": "Tone.PolySynth handles voice creation and allocation for any\n         instruments passed in as the second paramter. PolySynth is \n         not a synthesizer by itself, it merely manages voices of \n         one of the other types of synths, allowing any of the \n         monophonic synthesizers to be polyphonic.",
		"params": [
			{
				"type": [
					"number",
					"Object"
				],
				"optional": true,
				"defaultvalue": 4,
				"description": "The number of voices to create",
				"name": "polyphony"
			},
			{
				"type": [
					"function"
				],
				"optional": true,
				"defaultvalue": "Tone.Synth",
				"description": "The constructor of the voices\n                                           uses Tone.Synth by default.",
				"name": "voice"
			}
		],
		"examples": [
			"//a polysynth composed of 6 Voices of Synth\nvar synth = new Tone.PolySynth(6, Tone.Synth).toMaster();\n//set the attributes using the set interface\nsynth.set(\"detune\", -1200);\n//play a chord\nsynth.triggerAttackRelease([\"C4\", \"E4\", \"A4\"], \"4n\");"
		],
		"extends": "Tone.Instrument"
	},
	"Sampler": {
		"description": "Automatically interpolates between a set of pitched samples. Pass in an object which maps the note's pitch or midi value to the url, then you can trigger the attack and release of that note like other instruments. By automatically repitching the samples, it is possible to play pitches which were not explicitly included which can save loading time.\n       For sample or buffer playback where repitching is not necessary, use [Tone.Player](https://tonejs.github.io/docs/Player).",
		"params": [
			{
				"type": [
					"Object"
				],
				"description": "An object of samples mapping either Midi\n                        Note Numbers or Scientific Pitch Notation\n                        to the url of that sample.",
				"name": "samples"
			}
		],
		"examples": [
			"var sampler = new Tone.Sampler({\n\t\"C3\" : \"path/to/C3.mp3\",\n\t\"D#3\" : \"path/to/Dsharp3.mp3\",\n\t\"F#3\" : \"path/to/Fsharp3.mp3\",\n\t\"A3\" : \"path/to/A3.mp3\",\n}, function(){\n\t//sampler will repitch the closest sample\n\tsampler.triggerAttack(\"D3\")\n})"
		],
		"extends": "Tone.Instrument"
	},
	"Synth": {
		"description": "Tone.Synth is composed simply of a Tone.OmniOscillator\n         routed through a Tone.AmplitudeEnvelope. \n         <img src=\"https://docs.google.com/drawings/d/1-1_0YW2Z1J2EPI36P8fNCMcZG7N1w1GZluPs4og4evo/pub?w=1163&h=231\">",
		"params": [
			{
				"type": [
					"Object"
				],
				"optional": true,
				"description": "the options available for the synth \n                         see defaults below",
				"name": "options"
			}
		],
		"examples": [
			"var synth = new Tone.Synth().toMaster();\nsynth.triggerAttackRelease(\"C4\", \"8n\");"
		],
		"extends": "Tone.Monophonic"
	},
	"Zero": {
		"description": "Tone.Zero outputs 0's at audio-rate. The reason this has to be\n        it's own class is that many browsers optimize out Tone.Signal\n        with a value of 0 and will not process nodes further down the graph.",
		"extends": "Tone.SignalBase"
	},
	"Abs": {
		"description": "Return the absolute value of an incoming signal.",
		"examples": [
			"var signal = new Tone.Signal(-1);\nvar abs = new Tone.Abs();\nsignal.connect(abs);\n//the output of abs is 1. "
		],
		"extends": "Tone.SignalBase"
	},
	"Add": {
		"description": "Add a signal and a number or two signals. When no value is\n        passed into the constructor, Tone.Add will sum <code>input[0]</code>\n        and <code>input[1]</code>. If a value is passed into the constructor, \n        the it will be added to the input.",
		"params": [
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "If no value is provided, Tone.Add will sum the first\n                        and second inputs.",
				"name": "value"
			}
		],
		"examples": [
			"var signal = new Tone.Signal(2);\nvar add = new Tone.Add(2);\nsignal.connect(add);\n//the output of add equals 4\n ",
			"//if constructed with no arguments\n//it will add the first and second inputs\nvar add = new Tone.Add();\nvar sig0 = new Tone.Signal(3).connect(add, 0, 0);\nvar sig1 = new Tone.Signal(4).connect(add, 0, 1);\n//the output of add equals 7. "
		],
		"extends": "Tone.Signal"
	},
	"AudioToGain": {
		"description": "AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1]. \n        See Tone.GainToAudio.",
		"examples": [
			"var a2g = new Tone.AudioToGain();"
		],
		"extends": "Tone.SignalBase"
	},
	"EqualPowerGain": {
		"description": "Convert an incoming signal between 0, 1 to an equal power gain scale.",
		"examples": [
			"var eqPowGain = new Tone.EqualPowerGain();"
		],
		"extends": "Tone.SignalBase"
	},
	"Expr": {
		"description": "Evaluate an expression at audio rate. <br><br>\n        Parsing code modified from https://code.google.com/p/tapdigit/\n        Copyright 2011 2012 Ariya Hidayat, New BSD License",
		"params": [
			{
				"type": [
					"string"
				],
				"description": "the expression to generate",
				"name": "expr"
			}
		],
		"examples": [
			"//adds the signals from input[0] and input[1].\nvar expr = new Tone.Expr(\"$0 + $1\");"
		],
		"extends": "Tone.SignalBase"
	},
	"GainToAudio": {
		"description": "Maps a NormalRange [0, 1] to an AudioRange [-1, 1]. \n        See also Tone.AudioToGain.",
		"examples": [
			"var g2a = new Tone.GainToAudio();"
		],
		"extends": "Tone.SignalBase"
	},
	"GreaterThan": {
		"description": "Output 1 if the signal is greater than the value, otherwise outputs 0.\n         can compare two signals or a signal and a number.",
		"params": [
			{
				"type": [
					"number"
				],
				"optional": true,
				"defaultvalue": 0,
				"description": "the value to compare to the incoming signal",
				"name": "value"
			}
		],
		"examples": [
			"var gt = new Tone.GreaterThan(2);\nvar sig = new Tone.Signal(4).connect(gt);\n//output of gt is equal 1. "
		],
		"extends": "Tone.Signal"
	},
	"GreaterThanZero": {
		"description": "GreaterThanZero outputs 1 when the input is strictly greater than zero",
		"examples": [
			"var gt0 = new Tone.GreaterThanZero();\nvar sig = new Tone.Signal(0.01).connect(gt0);\n//the output of gt0 is 1. \nsig.value = 0;\n//the output of gt0 is 0. "
		],
		"extends": "Tone.SignalBase"
	},
	"Modulo": {
		"description": "Signal-rate modulo operator. Only works in AudioRange [-1, 1] and for modulus\n        values in the NormalRange.",
		"params": [
			{
				"type": [
					"NormalRange"
				],
				"description": "The modulus to apply.",
				"name": "modulus"
			}
		],
		"examples": [
			"var mod = new Tone.Modulo(0.2)\nvar sig = new Tone.Signal(0.5).connect(mod);\n//mod outputs 0.1"
		],
		"extends": "Tone.SignalBase"
	},
	"Multiply": {
		"description": "Multiply two incoming signals. Or, if a number is given in the constructor, \n         multiplies the incoming signal by that value.",
		"params": [
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "Constant value to multiple. If no value is provided,\n                        it will return the product of the first and second inputs",
				"name": "value"
			}
		],
		"examples": [
			"var mult = new Tone.Multiply();\nvar sigA = new Tone.Signal(3);\nvar sigB = new Tone.Signal(4);\nsigA.connect(mult, 0, 0);\nsigB.connect(mult, 0, 1);\n//output of mult is 12.\n ",
			"var mult = new Tone.Multiply(10);\nvar sig = new Tone.Signal(2).connect(mult);\n//the output of mult is 20. "
		],
		"extends": "Tone.Signal"
	},
	"Negate": {
		"description": "Negate the incoming signal. i.e. an input signal of 10 will output -10",
		"examples": [
			"var neg = new Tone.Negate();\nvar sig = new Tone.Signal(-2).connect(neg);\n//output of neg is positive 2. "
		],
		"extends": "Tone.SignalBase"
	},
	"Normalize": {
		"description": "Normalize takes an input min and max and maps it linearly to NormalRange [0,1]",
		"params": [
			{
				"type": [
					"number"
				],
				"description": "the min input value",
				"name": "inputMin"
			},
			{
				"type": [
					"number"
				],
				"description": "the max input value",
				"name": "inputMax"
			}
		],
		"examples": [
			"var norm = new Tone.Normalize(2, 4);\nvar sig = new Tone.Signal(3).connect(norm);\n//output of norm is 0.5. "
		],
		"extends": "Tone.SignalBase"
	},
	"Pow": {
		"description": "Pow applies an exponent to the incoming signal. The incoming signal\n        must be AudioRange.",
		"params": [
			{
				"type": [
					"Positive"
				],
				"description": "The exponent to apply to the incoming signal, must be at least 2.",
				"name": "exp"
			}
		],
		"examples": [
			"var pow = new Tone.Pow(2);\nvar sig = new Tone.Signal(0.5).connect(pow);\n//output of pow is 0.25. "
		],
		"extends": "Tone.SignalBase"
	},
	"Scale": {
		"description": "Performs a linear scaling on an input signal.\n         Scales a NormalRange input to between\n         outputMin and outputMax.",
		"params": [
			{
				"type": [
					"number"
				],
				"optional": true,
				"defaultvalue": 0,
				"description": "The output value when the input is 0.",
				"name": "outputMin"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"defaultvalue": 1,
				"description": "The output value when the input is 1.",
				"name": "outputMax"
			}
		],
		"examples": [
			"var scale = new Tone.Scale(50, 100);\nvar signal = new Tone.Signal(0.5).connect(scale);\n//the output of scale equals 75"
		],
		"extends": "Tone.SignalBase"
	},
	"ScaleExp": {
		"description": "Performs an exponential scaling on an input signal.\n         Scales a NormalRange value [0,1] exponentially\n         to the output range of outputMin to outputMax.",
		"params": [
			{
				"type": [
					"number"
				],
				"optional": true,
				"defaultvalue": 0,
				"description": "The output value when the input is 0.",
				"name": "outputMin"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"defaultvalue": 1,
				"description": "The output value when the input is 1.",
				"name": "outputMax"
			},
			{
				"type": [
					"number"
				],
				"optional": true,
				"defaultvalue": 2,
				"description": "The exponent which scales the incoming signal.",
				"name": "exponent"
			}
		],
		"examples": [
			"var scaleExp = new Tone.ScaleExp(0, 100, 2);\nvar signal = new Tone.Signal(0.5).connect(scaleExp);"
		],
		"extends": "Tone.SignalBase"
	},
	"Signal": {
		"description": "A signal is an audio-rate value. Tone.Signal is a core component of the library.\n         Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal\n         has all of the methods available to native Web Audio \n         [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)\n         as well as additional conveniences. Read more about working with signals \n         [here](https://github.com/Tonejs/Tone.js/wiki/Signals).",
		"params": [
			{
				"type": [
					"Number",
					"AudioParam"
				],
				"optional": true,
				"description": "Initial value of the signal. If an AudioParam\n                                    is passed in, that parameter will be wrapped\n                                    and controlled by the Signal.",
				"name": "value"
			},
			{
				"type": [
					"string"
				],
				"optional": true,
				"defaultvalue": "Number",
				"description": "unit The units the signal is in.",
				"name": "units"
			}
		],
		"examples": [
			"var signal = new Tone.Signal(10);"
		],
		"extends": "Tone.Param"
	},
	"SignalBase": {
		"description": "Base class for all Signals. Used Internally.",
		"extends": "Tone"
	},
	"Subtract": {
		"description": "Subtract the signal connected to <code>input[1]</code> from the signal connected \n        to <code>input[0]</code>. If an argument is provided in the constructor, the \n        signals <code>.value</code> will be subtracted from the incoming signal.",
		"params": [
			{
				"type": [
					"number"
				],
				"optional": true,
				"description": "The value to subtract from the incoming signal. If the value\n                        is omitted, it will subtract the second signal from the first.",
				"name": "value"
			}
		],
		"examples": [
			"var sub = new Tone.Subtract(1);\nvar sig = new Tone.Signal(4).connect(sub);\n//the output of sub is 3. \n ",
			"var sub = new Tone.Subtract();\nvar sigA = new Tone.Signal(10);\nvar sigB = new Tone.Signal(2.5);\nsigA.connect(sub, 0, 0);\nsigB.connect(sub, 0, 1);\n//output of sub is 7.5"
		],
		"extends": "Tone.Signal"
	},
	"TickSignal": {
		"description": "Tone.TickSignal extends Tone.TimelineSignal, but adds the capability\n       to calculate the number of elapsed ticks. exponential and target curves\n       are approximated with multiple linear ramps.\n\n       Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos, for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)\n       describing integrating timing functions for tempo calculations.",
		"params": [
			{
				"type": [
					"Number"
				],
				"description": "The initial value of the signal",
				"name": "value"
			}
		],
		"extends": "Tone.TimelineSignal"
	},
	"TimelineSignal": {
		"description": "A signal which adds the method getValueAtTime.\n        Code and inspiration from https://github.com/jsantell/web-audio-automation-timeline",
		"params": [
			{
				"type": [
					"Number"
				],
				"optional": true,
				"description": "The initial value of the signal",
				"name": "value"
			},
			{
				"type": [
					"String"
				],
				"optional": true,
				"description": "The conversion units of the signal.",
				"name": "units"
			}
		],
		"extends": "Tone.Signal"
	},
	"TransportTimelineSignal": {
		"description": "Tone.TransportTimelineSignal extends Tone.TimelineSignal, but adds the ability to synchronize the signal to the signal to the Tone.Transport",
		"extends": "Tone.TimelineSignal"
	},
	"WaveShaper": {
		"description": "Wraps the native Web Audio API \n        [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).",
		"params": [
			{
				"type": [
					"function",
					"Array",
					"Number"
				],
				"description": "The function used to define the values. \n                                   The mapping function should take two arguments: \n                                   the first is the value at the current position \n                                   and the second is the array position. \n                                   If the argument is an array, that array will be\n                                   set as the wave shaping function. The input\n                                   signal is an AudioRange [-1, 1] value and the output\n                                   signal can take on any numerical values.",
				"name": "mapping"
			},
			{
				"type": [
					"Number"
				],
				"optional": true,
				"defaultvalue": 1024,
				"description": "The length of the WaveShaperNode buffer.",
				"name": "bufferLen"
			}
		],
		"examples": [
			"var timesTwo = new Tone.WaveShaper(function(val){\n\treturn val * 2;\n}, 2048);\n ",
			"//a waveshaper can also be constructed with an array of values\nvar invert = new Tone.WaveShaper([1, -1]);"
		],
		"extends": "Tone.SignalBase"
	},
	"AMOscillator": {
		"description": "Tone.AMOscillator",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"description": "The starting frequency of the oscillator.",
				"name": "frequency"
			},
			{
				"type": [
					"String"
				],
				"description": "The type of the carrier oscillator.",
				"name": "type"
			},
			{
				"type": [
					"String"
				],
				"description": "The type of the modulator oscillator.",
				"name": "modulationType"
			}
		],
		"examples": [
			"//a sine oscillator frequency-modulated by a square wave\nvar fmOsc = new Tone.AMOscillator(\"Ab3\", \"sine\", \"square\").toMaster().start();"
		],
		"extends": "Tone.Oscillator"
	},
	"BufferSource": {
		"description": "Wrapper around the native BufferSourceNode.",
		"params": [
			{
				"type": [
					"AudioBuffer",
					"Tone.Buffer"
				],
				"description": "The buffer to play",
				"name": "buffer"
			},
			{
				"type": [
					"function"
				],
				"description": "The callback to invoke when the\n                              buffer is done playing.",
				"name": "onload"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"FMOscillator": {
		"description": "Tone.FMOscillator",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"description": "The starting frequency of the oscillator.",
				"name": "frequency"
			},
			{
				"type": [
					"String"
				],
				"description": "The type of the carrier oscillator.",
				"name": "type"
			},
			{
				"type": [
					"String"
				],
				"description": "The type of the modulator oscillator.",
				"name": "modulationType"
			}
		],
		"examples": [
			"//a sine oscillator frequency-modulated by a square wave\nvar fmOsc = new Tone.FMOscillator(\"Ab3\", \"sine\", \"square\").toMaster().start();"
		],
		"extends": "Tone.Source"
	},
	"FatOscillator": {
		"description": "Tone.FatOscillator",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"description": "The starting frequency of the oscillator.",
				"name": "frequency"
			},
			{
				"type": [
					"String"
				],
				"description": "The type of the carrier oscillator.",
				"name": "type"
			},
			{
				"type": [
					"String"
				],
				"description": "The type of the modulator oscillator.",
				"name": "modulationType"
			}
		],
		"examples": [
			"//a sine oscillator frequency-modulated by a square wave\nvar fmOsc = new Tone.FatOscillator(\"Ab3\", \"sine\", \"square\").toMaster().start();"
		],
		"extends": "Tone.Source"
	},
	"GrainPlayer": {
		"description": "Tone.GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).\n       Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the\n       amount of time each small chunk of audio is played for and the overlap is the\n       amount of crossfading transition time between successive grains.",
		"params": [
			{
				"type": [
					"String",
					"Tone.Buffer"
				],
				"description": "The url to load, or the Tone.Buffer to play.",
				"name": "url"
			},
			{
				"type": [
					"function"
				],
				"optional": true,
				"description": "The callback to invoke after the url is loaded.",
				"name": "callback"
			}
		],
		"extends": "Tone.Source"
	},
	"MultiPlayer": {
		"description": "Tone.MultiPlayer is well suited for one-shots, multi-sampled instruments\n        or any time you need to play a bunch of audio buffers.",
		"params": [
			{
				"type": [
					"Object",
					"Array",
					"Tone.Buffers"
				],
				"description": "The buffers which are available\n                                               to the MultiPlayer",
				"name": "buffers"
			},
			{
				"type": [
					"function"
				],
				"description": "The callback to invoke when all of the buffers are loaded.",
				"name": "onload"
			}
		],
		"examples": [
			"var multiPlayer = new MultiPlayer({\n\t\"kick\" : \"path/to/kick.mp3\",\n\t\"snare\" : \"path/to/snare.mp3\",\n}, function(){\n\tmultiPlayer.start(\"kick\");\n});\n ",
			"//can also store the values in an array\nvar multiPlayer = new MultiPlayer([\"path/to/kick.mp3\", \"path/to/snare.mp3\"], \nfunction(){\n\t//if an array is passed in, the samples are referenced to by index\n\tmultiPlayer.start(1);\n});"
		],
		"extends": "Tone",
		"deprecated": "Use [Tone.Players](Players) instead."
	},
	"Noise": {
		"description": "Tone.Noise is a noise generator. It uses looped noise buffers to save on performance.\n         Tone.Noise supports the noise types: \"pink\", \"white\", and \"brown\". Read more about\n         colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).",
		"params": [
			{
				"type": [
					"string"
				],
				"description": "the noise type (white|pink|brown)",
				"name": "type"
			}
		],
		"examples": [
			"//initialize the noise and start\nvar noise = new Tone.Noise(\"pink\").start();\n\n//make an autofilter to shape the noise\nvar autoFilter = new Tone.AutoFilter({\n\t\"frequency\" : \"8m\", \n\t\"min\" : 800, \n\t\"max\" : 15000\n}).connect(Tone.Master);\n\n//connect the noise\nnoise.connect(autoFilter);\n//start the autofilter LFO\nautoFilter.start()"
		],
		"extends": "Tone.Source"
	},
	"OmniOscillator": {
		"description": "Tone.OmniOscillator aggregates Tone.Oscillator, Tone.PulseOscillator,\n        Tone.PWMOscillator, Tone.FMOscillator, Tone.AMOscillator, and Tone.FatOscillator\n        into one class. The oscillator class can be changed by setting the `type`. \n        `omniOsc.type = \"pwm\"` will set it to the Tone.PWMOscillator. Prefixing\n        any of the basic types (\"sine\", \"square4\", etc.) with \"fm\", \"am\", or \"fat\"\n        will use the FMOscillator, AMOscillator or FatOscillator respectively. \n        For example: `omniOsc.type = \"fatsawtooth\"` will create set the oscillator\n        to a FatOscillator of type \"sawtooth\".",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"description": "The initial frequency of the oscillator.",
				"name": "frequency"
			},
			{
				"type": [
					"String"
				],
				"description": "The type of the oscillator.",
				"name": "type"
			}
		],
		"examples": [
			"var omniOsc = new Tone.OmniOscillator(\"C#4\", \"pwm\");"
		],
		"extends": "Tone.Source"
	},
	"Oscillator": {
		"description": "Tone.Oscillator supports a number of features including\n        phase rotation, multiple oscillator types (see Tone.Oscillator.type),\n        and Transport syncing (see Tone.Oscillator.syncFrequency).",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "Starting frequency",
				"name": "frequency"
			},
			{
				"type": [
					"string"
				],
				"optional": true,
				"description": "The oscillator type. Read more about type below.",
				"name": "type"
			}
		],
		"examples": [
			"//make and start a 440hz sine tone\nvar osc = new Tone.Oscillator(440, \"sine\").toMaster().start();"
		],
		"extends": "Tone.Source"
	},
	"PWMOscillator": {
		"description": "Tone.PWMOscillator modulates the width of a Tone.PulseOscillator \n        at the modulationFrequency. This has the effect of continuously\n        changing the timbre of the oscillator by altering the harmonics \n        generated.",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"description": "The starting frequency of the oscillator.",
				"name": "frequency"
			},
			{
				"type": [
					"Frequency"
				],
				"description": "The modulation frequency of the width of the pulse.",
				"name": "modulationFrequency"
			}
		],
		"examples": [
			"var pwm = new Tone.PWMOscillator(\"Ab3\", 0.3).toMaster().start();"
		],
		"extends": "Tone.Source"
	},
	"Player": {
		"description": "Tone.Player is an audio file player with start, loop, and stop functions.",
		"params": [
			{
				"type": [
					"string",
					"AudioBuffer"
				],
				"description": "Either the AudioBuffer or the url from\n                                 which to load the AudioBuffer",
				"name": "url"
			},
			{
				"type": [
					"function"
				],
				"optional": true,
				"description": "The function to invoke when the buffer is loaded. \n                           Recommended to use Tone.Buffer.on('load') instead.",
				"name": "onload"
			}
		],
		"examples": [
			"var player = new Tone.Player(\"./path/to/sample.mp3\").toMaster();\n//play as soon as the buffer is loaded\nplayer.autostart = true;"
		],
		"extends": "Tone.Source"
	},
	"Players": {
		"description": "Tone.Players combines multiple [Tone.Player](Player) objects.",
		"params": [
			{
				"type": [
					"Object"
				],
				"description": "An object mapping a name to a url.",
				"name": "urls"
			},
			{
				"type": [
					"function"
				],
				"optional": true,
				"description": "The function to invoke when the buffer is loaded.",
				"name": "onload"
			}
		],
		"extends": "Tone.AudioNode"
	},
	"PulseOscillator": {
		"description": "Tone.PulseOscillator is a pulse oscillator with control over pulse width,\n        also known as the duty cycle. At 50% duty cycle (width = 0.5) the wave is \n        a square and only odd-numbered harmonics are present. At all other widths \n        even-numbered harmonics are present. Read more \n        [here](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).",
		"params": [
			{
				"type": [
					"Frequency"
				],
				"optional": true,
				"description": "The frequency of the oscillator",
				"name": "frequency"
			},
			{
				"type": [
					"NormalRange"
				],
				"optional": true,
				"description": "The width of the pulse",
				"name": "width"
			}
		],
		"examples": [
			"var pulse = new Tone.PulseOscillator(\"E5\", 0.4).toMaster().start();"
		],
		"extends": "Tone.Source"
	},
	"Source": {
		"description": "Base class for sources. Sources have start/stop methods\n         and the ability to be synced to the\n         start/stop of Tone.Transport.",
		"examples": [
			"//Multiple state change events can be chained together,\n//but must be set in the correct order and with ascending times\n\n// OK\nstate.start().stop(\"+0.2\");\n// AND\nstate.start().stop(\"+0.2\").start(\"+0.4\").stop(\"+0.7\")\n\n// BAD\nstate.stop(\"+0.2\").start();\n// OR\nstate.start(\"+0.3\").stop(\"+0.2\");"
		],
		"extends": "Tone.AudioNode"
	},
	"UserMedia": {
		"description": "Tone.UserMedia uses MediaDevices.getUserMedia to open up\n         and external microphone or audio input. Check\n         [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)\n         to see which browsers are supported. Access to an external input\n         is limited to secure (HTTPS) connections.",
		"params": [
			{
				"type": [
					"Decibels"
				],
				"optional": true,
				"description": "The level of the input",
				"name": "volume"
			}
		],
		"examples": [
			"//list the inputs and open the third one\nvar motu = new Tone.UserMedia();\n\n//opening the input asks the user to activate their mic\nmotu.open().then(function(){\n\t//opening is activates the microphone\n\t//starting lets audio through\n\tmotu.start(10);\n});"
		],
		"extends": "Tone.AudioNode"
	},
	"Frequency": {
		"description": "Tone.Frequency is a primitive type for encoding Frequency values.\n        Eventually all time values are evaluated to hertz\n        using the `eval` method.",
		"params": [
			{
				"type": [
					"String",
					"Number"
				],
				"description": "The time value.",
				"name": "val"
			},
			{
				"type": [
					"String"
				],
				"optional": true,
				"description": "The units of the value.",
				"name": "units"
			}
		],
		"examples": [
			"Tone.Frequency(\"C3\") // 261\nTone.Frequency(38, \"midi\") //\nTone.Frequency(\"C3\").transpose(4);"
		],
		"extends": "Tone.TimeBase"
	},
	"Time": {
		"description": "Tone.Time is a primitive type for encoding Time values. \n        Eventually all time values are evaluated to seconds\n        using the `eval` method. Tone.Time can be constructed\n        with or without the `new` keyword. Tone.Time can be passed\n        into the parameter of any method which takes time as an argument.",
		"params": [
			{
				"type": [
					"String",
					"Number"
				],
				"description": "The time value.",
				"name": "val"
			},
			{
				"type": [
					"String"
				],
				"optional": true,
				"description": "The units of the value.",
				"name": "units"
			}
		],
		"examples": [
			"var t = Tone.Time(\"4n\");//encodes a quarter note\nt.mult(4); // multiply that value by 4\nt.toNotation(); //returns \"1m\""
		],
		"extends": "Tone.TimeBase"
	},
	"TimeBase": {
		"description": "Tone.TimeBase is a flexible encoding of time\n        which can be evaluated to and from a string.\n        Parsing code modified from https://code.google.com/p/tapdigit/\n        Copyright 2011 2012 Ariya Hidayat, New BSD License",
		"params": [
			{
				"type": [
					"Time"
				],
				"description": "The time value as a number or string",
				"name": "val"
			},
			{
				"type": [
					"String"
				],
				"optional": true,
				"description": "Unit values",
				"name": "units"
			}
		],
		"examples": [
			"Tone.TimeBase(4, \"n\")\nTone.TimeBase(2, \"t\")\nTone.TimeBase(\"2t\").add(\"1m\")\nTone.TimeBase(\"2t + 1m\");"
		],
		"extends": "Tone"
	},
	"TransportTime": {
		"description": "Tone.TransportTime is a the time along the Transport's\n        timeline. It is similar to Tone.Time, but instead of evaluating\n        against the AudioContext's clock, it is evaluated against\n        the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).",
		"params": [
			{
				"type": [
					"Time"
				],
				"description": "The time value as a number or string",
				"name": "val"
			},
			{
				"type": [
					"String"
				],
				"optional": true,
				"description": "Unit values",
				"name": "units"
			}
		],
		"extends": "Tone.Time"
	}
}